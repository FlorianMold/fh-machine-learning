{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 2 - More comparative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The music dataset is used!\n",
      "/home/user/projects/private/fh/fh-machine-learning/data/GTZANmp3_22khz\n",
      "/home/user/projects/private/fh/fh-machine-learning/ex2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from IPython.core.display_functions import display\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# disable all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "matrikelNumber = 11776836\n",
    "isEvenMatrikelNumber = matrikelNumber % 2 == 0\n",
    "dataset = \"music\" if True else \"image\"\n",
    "print(\"The\", dataset, \"dataset is used!\")\n",
    "\n",
    "imageFolder = \"GTZANmp3_22khz\"\n",
    "print(os.getcwd())\n",
    "if imageFolder in os.getcwd():\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "    os.chdir('ex2/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Small dataset: HR-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the first step, the dataset was cleaned. I filtered data, that is not very expressive and classified the absences into different classes. I also one hot encoded the dataset. The target feature is the `RaceDesc_White`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drop all continuous columns from the dataset, I can't encode these columns well. Categorization of these columns will not work, because every value is very different.\n"
     ]
    },
    {
     "data": {
      "text/plain": "   MarriedID_1  MaritalStatusID_1  MaritalStatusID_2  MaritalStatusID_3  \\\n0            0                  0                  0                  0   \n1            1                  1                  0                  0   \n2            1                  1                  0                  0   \n3            1                  1                  0                  0   \n4            0                  0                  1                  0   \n\n   MaritalStatusID_4  GenderID_1  EmpStatusID_2  EmpStatusID_3  EmpStatusID_4  \\\n0                  0           1              0              0              0   \n1                  0           1              0              0              0   \n2                  0           0              0              0              0   \n3                  0           0              0              0              0   \n4                  0           0              0              0              0   \n\n   EmpStatusID_5  ...  DaysLateLast30_1  DaysLateLast30_2  DaysLateLast30_3  \\\n0              0  ...                 0                 0                 0   \n1              1  ...                 0                 0                 0   \n2              1  ...                 0                 0                 0   \n3              0  ...                 0                 0                 0   \n4              1  ...                 0                 0                 0   \n\n   DaysLateLast30_4  DaysLateLast30_5  DaysLateLast30_6  absences_label_0-5  \\\n0                 0                 0                 0                   0   \n1                 0                 0                 0                   0   \n2                 0                 0                 0                   0   \n3                 0                 0                 0                   0   \n4                 0                 0                 0                   0   \n\n   absences_label_11-15  absences_label_15+  absences_label_6-10  \n0                     0                   0                    0  \n1                     0                   1                    0  \n2                     0                   0                    0  \n3                     0                   1                    0  \n4                     0                   0                    0  \n\n[5 rows x 378 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MarriedID_1</th>\n      <th>MaritalStatusID_1</th>\n      <th>MaritalStatusID_2</th>\n      <th>MaritalStatusID_3</th>\n      <th>MaritalStatusID_4</th>\n      <th>GenderID_1</th>\n      <th>EmpStatusID_2</th>\n      <th>EmpStatusID_3</th>\n      <th>EmpStatusID_4</th>\n      <th>EmpStatusID_5</th>\n      <th>...</th>\n      <th>DaysLateLast30_1</th>\n      <th>DaysLateLast30_2</th>\n      <th>DaysLateLast30_3</th>\n      <th>DaysLateLast30_4</th>\n      <th>DaysLateLast30_5</th>\n      <th>DaysLateLast30_6</th>\n      <th>absences_label_0-5</th>\n      <th>absences_label_11-15</th>\n      <th>absences_label_15+</th>\n      <th>absences_label_6-10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 378 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrDataset = pd.read_csv('../data/HRDataset_v14.csv', sep=',')\n",
    "hrDataset.sample(frac=1, random_state=matrikelNumber).reset_index(drop=True)\n",
    "\n",
    "# Clean the dataset\n",
    "print(\n",
    "    \"I drop all continuous columns from the dataset, I can't encode these columns well. Categorization of these columns will not work, because every value is very different.\")\n",
    "filteredHR = hrDataset.drop(\"EmpID\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"Employee_Name\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"DateofTermination\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"LastPerformanceReview_Date\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"DateofHire\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"EngagementSurvey\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"Salary\", axis=1)\n",
    "filteredHR = filteredHR.drop(\"DOB\", axis=1)\n",
    "\n",
    "filteredHR['absences_label'] = filteredHR['Absences'].apply(lambda value: '0-14'\n",
    "if value <= 4 else '0-5'\n",
    "if value <= 5 else '6-10'\n",
    "if value <= 10 else '11-15'\n",
    "if value <= 14 else '15+')\n",
    "\n",
    "filteredHR = filteredHR.drop(\"Absences\", axis=1)\n",
    "# filteredHR.head()\n",
    "\n",
    "# One hot encode the dataset\n",
    "encodedHR = pd.get_dummies(filteredHR, columns=filteredHR.columns, drop_first=True)\n",
    "\n",
    "# Split the dataset\n",
    "hrXAxis = encodedHR.drop('RaceDesc_White', axis=1)\n",
    "hrYAxis = encodedHR['RaceDesc_White']\n",
    "\n",
    "encodedHR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Large dataset: Census income"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the first step, the dataset was cleaned. I filtered data, that is not very expressive and classified the age and wage into different classes. I also one hot encoded the dataset. The target feature is the `race_ White`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     class of worker_ Local government  class of worker_ Private  \\\n5                                    0                         1   \n8                                    1                         0   \n22                                   0                         1   \n49                                   0                         1   \n147                                  0                         0   \n\n     class of worker_ State government  detailed industry recode_2  \\\n5                                    0                           0   \n8                                    0                           0   \n22                                   0                           0   \n49                                   0                           0   \n147                                  1                           0   \n\n     detailed industry recode_3  detailed industry recode_4  \\\n5                             0                           0   \n8                             0                           0   \n22                            0                           0   \n49                            0                           0   \n147                           0                           0   \n\n     detailed industry recode_5  detailed industry recode_6  \\\n5                             0                           0   \n8                             0                           0   \n22                            0                           0   \n49                            0                           0   \n147                           0                           0   \n\n     detailed industry recode_7  detailed industry recode_8  ...  \\\n5                             0                           0  ...   \n8                             0                           0  ...   \n22                            0                           0  ...   \n49                            0                           0  ...   \n147                           0                           0  ...   \n\n     weeks worked in year_49  weeks worked in year_50  \\\n5                          0                        0   \n8                          0                        0   \n22                         0                        0   \n49                         0                        0   \n147                        0                        0   \n\n     weeks worked in year_51  weeks worked in year_52  age_label_25-54  \\\n5                          0                        1                1   \n8                          0                        1                1   \n22                         0                        0                0   \n49                         0                        1                0   \n147                        0                        0                0   \n\n     age_label_55-64  age_label_65 years and over  wage_label_3001-6000  \\\n5                  0                            0                     0   \n8                  0                            0                     0   \n22                 1                            0                     0   \n49                 0                            1                     0   \n147                0                            0                     0   \n\n     wage_label_6001-7000  wage_label_7001-9000+  \n5                       0                      0  \n8                       0                      0  \n22                      0                      0  \n49                      0                      0  \n147                     0                      0  \n\n[5 rows x 911 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class of worker_ Local government</th>\n      <th>class of worker_ Private</th>\n      <th>class of worker_ State government</th>\n      <th>detailed industry recode_2</th>\n      <th>detailed industry recode_3</th>\n      <th>detailed industry recode_4</th>\n      <th>detailed industry recode_5</th>\n      <th>detailed industry recode_6</th>\n      <th>detailed industry recode_7</th>\n      <th>detailed industry recode_8</th>\n      <th>...</th>\n      <th>weeks worked in year_49</th>\n      <th>weeks worked in year_50</th>\n      <th>weeks worked in year_51</th>\n      <th>weeks worked in year_52</th>\n      <th>age_label_25-54</th>\n      <th>age_label_55-64</th>\n      <th>age_label_65 years and over</th>\n      <th>wage_label_3001-6000</th>\n      <th>wage_label_6001-7000</th>\n      <th>wage_label_7001-9000+</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 911 columns</p>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censusIncome = pd.read_csv('../data/census-income.data', sep=',')\n",
    "censusIncome.sample(frac=1, random_state=matrikelNumber).reset_index(drop=True)\n",
    "\n",
    "censusIncome['age_label'] = censusIncome['age'].apply(lambda value: '0-14'\n",
    "if value <= 14 else '15-24'\n",
    "if value <= 24 else '25-54'\n",
    "if value <= 54 else '55-64'\n",
    "if value <= 64 else '65 years and over')\n",
    "\n",
    "censusIncome['wage_label'] = censusIncome['wage per hour'].apply(lambda value: '0-3000'\n",
    "if value <= 3000 else '3001-6000'\n",
    "if value <= 6000 else '6001-7000'\n",
    "if value <= 7000 else '7001-9000+')\n",
    "\n",
    "filteredCensus = censusIncome[\n",
    "    (censusIncome['class of worker'] != ' Not in universe') &\n",
    "    (censusIncome['education'] != ' Children') &\n",
    "    (censusIncome['wage per hour'] > 0) &\n",
    "    (censusIncome['weeks worked in year'] > 0)\n",
    "    ]\n",
    "\n",
    "filteredCensus = filteredCensus.drop(\"age\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"wage per hour\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"year\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"ignore\", axis=1)\n",
    "filteredCensus = filteredCensus.drop(\"instance weight\", axis=1)\n",
    "\n",
    "# filteredCensus.head()\n",
    "\n",
    "# One hot encode the dataset\n",
    "encodedIncome = pd.get_dummies(filteredCensus, columns=filteredCensus.columns, drop_first=True)\n",
    "\n",
    "# Split the dataset\n",
    "censusIncomeXAxis = encodedIncome.drop('race_ White', axis=1)\n",
    "censusIncomeYAxis = encodedIncome['race_ White']\n",
    "\n",
    "encodedIncome.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Music dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following features were extracted from the music dataset:\n",
    "\n",
    "- Beats per minute\n",
    "- Beats per minute statistics\n",
    "- Chroma\n",
    "- MFCC\n",
    "\n",
    "The target is the genre of the song."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files\n",
      "\n",
      "Found the following classes: ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "Transformed labels (first elements: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "... done label encoding\n"
     ]
    }
   ],
   "source": [
    "# We need to construct our data set; unfortunately, we don't simply have a \"loadGTZanDataSet()\" function in SK-learn...\n",
    "# So we need to\n",
    "## Download our data set & extract it (one-time effort)\n",
    "## Run an audio feature extraction\n",
    "## Create the create the ground truth (label assignment, target, ...)\n",
    "\n",
    "\n",
    "# path to our audio folder\n",
    "# For the first run, download the images from http://kronos.ifs.tuwien.ac.at/GTZANmp3_22khz.zip, and unzip them to your folder\n",
    "imagePath = \"../data/GTZANmp3_22khz/\"\n",
    "\n",
    "# Find all songs in that folder; there are like 1.000 different ways to do this in Python, we chose this one :-)\n",
    "os.chdir(imagePath)\n",
    "fileNames = glob.glob(\"*/*.mp3\")\n",
    "numberOfFiles = len(fileNames)\n",
    "targetLabels = []\n",
    "\n",
    "print(\"Found \" + str(numberOfFiles) + \" files\\n\")\n",
    "\n",
    "# The first step - create the ground truth (label assignment, target, ...)\n",
    "# For that, iterate over the files, and obtain the class label for each file\n",
    "# Basically, the class name is in the full path name, so we simply use that\n",
    "for fileName in fileNames:\n",
    "    pathSepIndex = fileName.index(\"/\")\n",
    "    targetLabels.append(fileName[:pathSepIndex])\n",
    "\n",
    "# sk-learn can only handle labels in numeric format - we have them as strings though...\n",
    "# Thus we use the LabelEncoder, which does a mapping to Integer numbers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(targetLabels)  # this basically finds all unique class names, and assigns them to the numbers\n",
    "print(\"Found the following classes: \" + str(list(le.classes_)))\n",
    "\n",
    "# now we transform our labels to integers\n",
    "musicTarget = le.transform(targetLabels)\n",
    "print(\"Transformed labels (first elements: \" + str(musicTarget[0:150]))\n",
    "\n",
    "# If we want to find again the label for an integer value, we can do something like this:\n",
    "# print list(le.inverse_transform([0, 18, 1]))\n",
    "\n",
    "print(\"... done label encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features using librosa (2022-05-30 21:23:20.893987)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11% (115 of 1000) |##                   | Elapsed Time: 0:00:55 ETA:   0:06:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors with beat interval in file classical/classical.00050.mp3, index 115, using 0 values instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:07:55 Time:  0:07:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... done (2022-05-30 21:31:16.579348)\n"
     ]
    }
   ],
   "source": [
    "# Now we do the actual feature extraction\n",
    "\n",
    "# This is a helper function that computes the differences between adjacent array values\n",
    "def differences(seq):\n",
    "    iterable = iter(seq)\n",
    "    prev = next(iterable)\n",
    "    for element in iterable:\n",
    "        yield element - prev\n",
    "        prev = element\n",
    "\n",
    "\n",
    "# This is a helper function that computes various statistical moments over a series of values, including mean, median, var, min, max, skewness and kurtosis (a total of 7 values)\n",
    "def statistics(numericList):\n",
    "    return [np.mean(numericList), np.median(numericList), np.var(numericList), np.float64(skew(numericList)),\n",
    "            np.float64(kurtosis(numericList)), np.min(numericList), np.max(numericList)]\n",
    "\n",
    "\n",
    "print(\"Extracting features using librosa\" + \" (\" + str(datetime.datetime.now()) + \")\")\n",
    "\n",
    "# compute some features based on BPMs, MFCCs, Chroma\n",
    "data_bpm = []\n",
    "data_bpm_statistics = []\n",
    "data_mfcc = []\n",
    "data_chroma = []\n",
    "\n",
    "# This takes a bit, so let's show it with a progress bar\n",
    "with ProgressBar(max_value=len(fileNames)) as bar:\n",
    "    for indexSample, fileName in enumerate(fileNames):\n",
    "        # Load the audio as a waveform `y`, store the sampling rate as `sr`\n",
    "        y, sr = librosa.load(fileName)\n",
    "\n",
    "        # run the default beat tracker\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        # from this, we simply use the tempo as BPM feature\n",
    "        data_bpm.append([tempo])\n",
    "\n",
    "        # Then we compute a few statistics on the beat timings\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        # from the timings, compute the time differences between the beats\n",
    "        beat_intervals = np.array(deque(differences(beat_times)))\n",
    "\n",
    "        # And from this, take some statistics\n",
    "        # There might be a few files where the beat timings are not determined properly; we ignore them, resp. give them 0 values\n",
    "        if len(beat_intervals) < 1:\n",
    "            print(\"Errors with beat interval in file \" + fileName + \", index \" + str(\n",
    "                indexSample) + \", using 0 values instead\")\n",
    "            data_bpm_statistics.append([tempo, 0, 0, 0, 0, 0, 0, 0])\n",
    "        else:\n",
    "            bpm_statisticsVector = []\n",
    "            bpm_statisticsVector.append(tempo)  # we also include the raw value of tempo\n",
    "            for stat in statistics(beat_intervals):  # in case the timings are ok, we actually compute the statistics\n",
    "                bpm_statisticsVector.append(stat)  # and append it to the vector, which finally has 1 + 7 features\n",
    "            data_bpm_statistics.append(bpm_statisticsVector)\n",
    "\n",
    "        # Next feature are MFCCs; we take 12 coefficients; for each coefficient, we have around 40 values per second\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=12)\n",
    "        mfccVector = []\n",
    "        for mfccCoefficient in mfccs:  # we transform this time series by taking again statistics over the values\n",
    "            mfccVector.append(statistics(mfccCoefficient))\n",
    "\n",
    "        # Finally, this vector should have 12 * 7 features\n",
    "        data_mfcc.append(np.array(mfccVector).flatten())\n",
    "\n",
    "        # Last feature set - chroma (which is roughly similar to actual notes)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chromaVector = []\n",
    "        for chr in chroma:  # similar to before, we get a number of time-series\n",
    "            chromaVector.append(statistics(chr))  # and we resolve that by taking statistics over the time series\n",
    "        # Finally, this vector should be be 12 * 7 features\n",
    "        data_chroma.append(np.array(chromaVector).flatten())\n",
    "\n",
    "        bar.update(indexSample)\n",
    "\n",
    "print(\".... done\" + \" (\" + str(datetime.datetime.now()) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "bestResult = {\n",
    "    'f1Score': 0,\n",
    "    'yTest': 0,\n",
    "    'yTestPredicted': 0,\n",
    "    'algorithm': '',\n",
    "    'dataset': ''\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### k-NN (k-nearest-neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def kNearestNeighbours(datasetName, kNeighbours, XTrain, XTest, yTrain, yTest):\n",
    "    results = []\n",
    "\n",
    "    for k in kNeighbours:\n",
    "        print(datasetName)\n",
    "        print('kNN with', k, 'neighbours')\n",
    "        knnClassifier = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n",
    "\n",
    "        # Train the classifier\n",
    "        startTime = time.time()\n",
    "        knnClassifier.fit(XTrain, yTrain.ravel())\n",
    "        endTime = time.time()\n",
    "        trainTime = endTime - startTime\n",
    "\n",
    "        # Predict\n",
    "        startTime = time.time()\n",
    "        predicted = knnClassifier.predict(XTest)\n",
    "        endTime = time.time()\n",
    "        predictionTime = endTime - startTime\n",
    "\n",
    "        # Effectiveness measurement\n",
    "        accuracyScore = accuracy_score(yTest, predicted)\n",
    "        f1Score = f1_score(yTest, predicted, average='weighted')\n",
    "\n",
    "        formattedTrainTime = str(\"{:.3f}s\".format(trainTime))\n",
    "        formattedPredictionTime = str(\"{:.3f}s\".format(predictionTime))\n",
    "        formattedAccuracyScore = str(\"{:.3f}%\".format(accuracyScore * 100))\n",
    "        formattedF1Score = str(\"{:.3f}%\".format(f1Score * 100))\n",
    "\n",
    "        print('Training time:', formattedTrainTime)\n",
    "        print('Testing time:', formattedPredictionTime)\n",
    "        print()\n",
    "\n",
    "        print('Accuracy:', formattedAccuracyScore)\n",
    "        print('F1 score:', formattedF1Score)\n",
    "        print('------------------------------------')\n",
    "\n",
    "        result = {\n",
    "            'datasetName': datasetName,\n",
    "            'algorithmName': 'kNN with \"' + str(k) + '\" neighbours',\n",
    "            'neighbours': k,\n",
    "            'accuracyScore': formattedAccuracyScore,\n",
    "            'f1Score': formattedF1Score,\n",
    "            'trainTime': formattedTrainTime,\n",
    "            'predictionTime': formattedPredictionTime\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "        if datasetName != 'HR' and datasetName != 'Census Income':\n",
    "            if bestResult is None or bestResult['f1Score'] < f1Score:\n",
    "                bestResult['f1Score'] = f1Score\n",
    "                bestResult['yTestPredicted'] = predicted\n",
    "                bestResult['yTest'] = yTest\n",
    "                bestResult['algorithm'] = 'kNN'\n",
    "                bestResult['dataset'] = datasetName\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(datasetName, alphaValues, XTrain, XTest, yTrain, yTest):\n",
    "    results = []\n",
    "\n",
    "    for alpha in alphaValues:\n",
    "        print(datasetName)\n",
    "        print('Perceptron with alpha', alpha)\n",
    "        perceptronClassifier = Perceptron(alpha=alpha, random_state=matrikelNumber)\n",
    "\n",
    "        # Train the classifier\n",
    "        startTime = time.time()\n",
    "        perceptronClassifier.fit(XTrain, yTrain.ravel())\n",
    "        endTime = time.time()\n",
    "        trainTime = endTime - startTime\n",
    "\n",
    "        # Predict\n",
    "        startTime = time.time()\n",
    "        predicted = perceptronClassifier.predict(XTest)\n",
    "        endTime = time.time()\n",
    "        predictionTime = endTime - startTime\n",
    "\n",
    "        # Effectiveness measurement\n",
    "        accuracyScore = accuracy_score(yTest, predicted)\n",
    "        f1Score = f1_score(yTest, predicted, average='weighted')\n",
    "\n",
    "        formattedTrainTime = str(\"{:.3f}s\".format(trainTime))\n",
    "        formattedPredictionTime = str(\"{:.3f}s\".format(predictionTime))\n",
    "        formattedAccuracyScore = str(\"{:.3f}%\".format(accuracyScore * 100))\n",
    "        formattedF1Score = str(\"{:.3f}%\".format(f1Score * 100))\n",
    "\n",
    "        print('Training time:', formattedTrainTime)\n",
    "        print('Testing time:', formattedPredictionTime)\n",
    "        print()\n",
    "\n",
    "        print('Accuracy:', formattedAccuracyScore)\n",
    "        print('F1 score:', formattedF1Score)\n",
    "        print('------------------------------------')\n",
    "\n",
    "        result = {\n",
    "            'datasetName': datasetName,\n",
    "            'algorithmName': 'Perceptron with \"' + str(alpha) + '\" alpha',\n",
    "            'alpha': alpha,\n",
    "            'accuracyScore': formattedAccuracyScore,\n",
    "            'f1Score': formattedF1Score,\n",
    "            'trainTime': formattedTrainTime,\n",
    "            'predictionTime': formattedPredictionTime\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        if datasetName != 'HR' and datasetName != 'Census Income':\n",
    "            if bestResult is None or bestResult['f1Score'] < f1Score:\n",
    "                bestResult['f1Score'] = f1Score\n",
    "                bestResult['yTestPredicted'] = predicted\n",
    "                bestResult['yTest'] = yTest\n",
    "                bestResult['algorithm'] = 'Perceptron'\n",
    "                bestResult['dataset'] = datasetName\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decisionTree(datasetName, maxFeatureValues, XTrain, XTest, yTrain, yTest):\n",
    "    results = []\n",
    "\n",
    "    for maxFeatures in maxFeatureValues:\n",
    "        print(datasetName)\n",
    "        print('Decision Tree with max features', maxFeatures)\n",
    "\n",
    "        decisionTreeClassifier = DecisionTreeClassifier(max_features=maxFeatures, random_state=matrikelNumber)\n",
    "\n",
    "        # Train the classifier\n",
    "        startTime = time.time()\n",
    "        decisionTreeClassifier.fit(XTrain, yTrain.ravel())\n",
    "        endTime = time.time()\n",
    "        trainTime = endTime - startTime\n",
    "\n",
    "        # Predict\n",
    "        startTime = time.time()\n",
    "        predicted = decisionTreeClassifier.predict(XTest)\n",
    "        endTime = time.time()\n",
    "        predictionTime = endTime - startTime\n",
    "\n",
    "        # Effectiveness measurement\n",
    "        accuracyScore = accuracy_score(yTest, predicted)\n",
    "        f1Score = f1_score(yTest, predicted, average='weighted')\n",
    "\n",
    "        formattedTrainTime = str(\"{:.3f}s\".format(trainTime))\n",
    "        formattedPredictionTime = str(\"{:.3f}s\".format(predictionTime))\n",
    "        formattedAccuracyScore = str(\"{:.3f}%\".format(accuracyScore * 100))\n",
    "        formattedF1Score = str(\"{:.3f}%\".format(f1Score * 100))\n",
    "\n",
    "        print('Training time:', formattedTrainTime)\n",
    "        print('Testing time:', formattedPredictionTime)\n",
    "        print()\n",
    "\n",
    "        print('Accuracy:', formattedAccuracyScore)\n",
    "        print('F1 score:', formattedF1Score)\n",
    "        print('------------------------------------')\n",
    "\n",
    "        result = {\n",
    "            'datasetName': datasetName,\n",
    "            'algorithmName': 'Decision Tree with \"' + str(maxFeatures) + '\" max features',\n",
    "            'maxFeatures': maxFeatures,\n",
    "            'accuracyScore': formattedAccuracyScore,\n",
    "            'f1Score': formattedF1Score,\n",
    "            'trainTime': formattedTrainTime,\n",
    "            'predictionTime': formattedPredictionTime\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        if datasetName != 'HR' and datasetName != 'Census Income':\n",
    "            if bestResult is None or bestResult['f1Score'] < f1Score:\n",
    "                bestResult['f1Score'] = f1Score\n",
    "                bestResult['yTestPredicted'] = predicted\n",
    "                bestResult['yTest'] = yTest\n",
    "                bestResult['algorithm'] = 'Decision Tree'\n",
    "                bestResult['dataset'] = datasetName\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SVM (Support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def supportVectorMachine(datasetName, XTrain, XTest, yTrain, yTest):\n",
    "    print(datasetName)\n",
    "    print('Support Vector Machine')\n",
    "\n",
    "    results = []\n",
    "\n",
    "    svmClassifier = make_pipeline(StandardScaler(), SVC(random_state=matrikelNumber))\n",
    "\n",
    "    # Train the classifier\n",
    "    startTime = time.time()\n",
    "    svmClassifier.fit(XTrain, yTrain.ravel())\n",
    "    endTime = time.time()\n",
    "    trainTime = endTime - startTime\n",
    "\n",
    "    # Predict\n",
    "    startTime = time.time()\n",
    "    predicted = svmClassifier.predict(XTest)\n",
    "    endTime = time.time()\n",
    "    predictionTime = endTime - startTime\n",
    "\n",
    "    # Effectiveness measurement\n",
    "    accuracyScore = accuracy_score(yTest, predicted)\n",
    "    f1Score = f1_score(yTest, predicted, average='weighted')\n",
    "\n",
    "    formattedTrainTime = str(\"{:.3f}s\".format(trainTime))\n",
    "    formattedPredictionTime = str(\"{:.3f}s\".format(predictionTime))\n",
    "    formattedAccuracyScore = str(\"{:.3f}%\".format(accuracyScore * 100))\n",
    "    formattedF1Score = str(\"{:.3f}%\".format(f1Score * 100))\n",
    "\n",
    "    print('Training time:', formattedTrainTime)\n",
    "    print('Testing time:', formattedPredictionTime)\n",
    "    print()\n",
    "\n",
    "    print('Accuracy:', formattedAccuracyScore)\n",
    "    print('F1 score:', formattedF1Score)\n",
    "    print('------------------------------------')\n",
    "\n",
    "    result = {\n",
    "        'datasetName': datasetName,\n",
    "        'algorithmName': 'SVM',\n",
    "        'accuracyScore': formattedAccuracyScore,\n",
    "        'f1Score': formattedF1Score,\n",
    "        'trainTime': formattedTrainTime,\n",
    "        'predictionTime': formattedPredictionTime\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    if datasetName != 'HR' and datasetName != 'Census Income':\n",
    "        if bestResult is None or bestResult['f1Score'] < f1Score:\n",
    "            bestResult['f1Score'] = f1Score\n",
    "            bestResult['yTestPredicted'] = predicted\n",
    "            bestResult['yTest'] = yTest\n",
    "            bestResult['algorithm'] = 'SVM'\n",
    "            bestResult['dataset'] = datasetName\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def randomForest(datasetName, numberOfTrees, maxFeatureValues, XTrain, XTest, yTrain, yTest):\n",
    "    results = []\n",
    "\n",
    "    for numberOfTreeElements in numberOfTrees:\n",
    "        for maxFeatureValue in maxFeatureValues:\n",
    "            print(datasetName)\n",
    "            print('Random forest with', numberOfTreeElements, 'trees and', maxFeatureValue, 'max features')\n",
    "\n",
    "            randomForestClassifier = RandomForestClassifier(\n",
    "                n_estimators=numberOfTreeElements,\n",
    "                max_features=maxFeatureValue,\n",
    "                random_state=matrikelNumber\n",
    "            )\n",
    "\n",
    "            # Train the classifier\n",
    "            startTime = time.time()\n",
    "            randomForestClassifier.fit(XTrain, yTrain.ravel())\n",
    "            endTime = time.time()\n",
    "            trainTime = endTime - startTime\n",
    "\n",
    "            # Predict\n",
    "            startTime = time.time()\n",
    "            predicted = randomForestClassifier.predict(XTest)\n",
    "            endTime = time.time()\n",
    "            predictionTime = endTime - startTime\n",
    "\n",
    "            # Effectiveness measurement\n",
    "            accuracyScore = accuracy_score(yTest, predicted)\n",
    "            f1Score = f1_score(yTest, predicted, average='weighted')\n",
    "\n",
    "            formattedTrainTime = str(\"{:.3f}s\".format(trainTime))\n",
    "            formattedPredictionTime = str(\"{:.3f}s\".format(predictionTime))\n",
    "            formattedAccuracyScore = str(\"{:.3f}%\".format(accuracyScore * 100))\n",
    "            formattedF1Score = str(\"{:.3f}%\".format(f1Score * 100))\n",
    "\n",
    "            print('Training time:', formattedTrainTime)\n",
    "            print('Testing time:', formattedPredictionTime)\n",
    "            print()\n",
    "\n",
    "            print('Accuracy:', formattedAccuracyScore)\n",
    "            print('F1 score:', formattedF1Score)\n",
    "            print('------------------------------------')\n",
    "\n",
    "            result = {\n",
    "                'datasetName': datasetName,\n",
    "                'algorithmName': 'Random F. (\"' + str(numberOfTreeElements) + '\" trees, \"' + str(\n",
    "                    maxFeatureValue) + '\" max feature)',\n",
    "                'numberOfTreeElements': numberOfTreeElements,\n",
    "                'maxFeatureValue': maxFeatureValue,\n",
    "                'accuracyScore': formattedAccuracyScore,\n",
    "                'f1Score': formattedF1Score,\n",
    "                'trainTime': formattedTrainTime,\n",
    "                'predictionTime': formattedPredictionTime\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "            if datasetName != 'HR' and datasetName != 'Census Income':\n",
    "                if bestResult is None or bestResult['f1Score'] < f1Score:\n",
    "                    bestResult['f1Score'] = f1Score\n",
    "                    bestResult['yTestPredicted'] = predicted\n",
    "                    bestResult['yTest'] = yTest\n",
    "                    bestResult['algorithm'] = 'Random Forest'\n",
    "                    bestResult['dataset'] = datasetName\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we apply our classifiers to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census Income\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.707s\n",
      "Testing time: 34.247s\n",
      "\n",
      "Accuracy: 83.943%\n",
      "F1 score: 84.432%\n",
      "------------------------------------\n",
      "Census Income\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.640s\n",
      "Testing time: 34.238s\n",
      "\n",
      "Accuracy: 87.847%\n",
      "F1 score: 86.309%\n",
      "------------------------------------\n",
      "Census Income\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.655s\n",
      "Testing time: 34.467s\n",
      "\n",
      "Accuracy: 88.205%\n",
      "F1 score: 85.552%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.185s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 98.103%\n",
      "F1 score: 98.093%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.161s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 98.103%\n",
      "F1 score: 98.093%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.162s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 98.103%\n",
      "F1 score: 98.093%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Decision Tree with max features None\n",
      "Training time: 0.722s\n",
      "Testing time: 0.010s\n",
      "\n",
      "Accuracy: 97.305%\n",
      "F1 score: 97.323%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.055s\n",
      "Testing time: 0.013s\n",
      "\n",
      "Accuracy: 87.902%\n",
      "F1 score: 87.800%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.039s\n",
      "Testing time: 0.010s\n",
      "\n",
      "Accuracy: 86.142%\n",
      "F1 score: 85.820%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Support Vector Machine\n",
      "Training time: 14.095s\n",
      "Testing time: 9.431s\n",
      "\n",
      "Accuracy: 96.728%\n",
      "F1 score: 96.573%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.283s\n",
      "Testing time: 0.022s\n",
      "\n",
      "Accuracy: 96.893%\n",
      "F1 score: 96.775%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.205s\n",
      "Testing time: 0.023s\n",
      "\n",
      "Accuracy: 92.356%\n",
      "F1 score: 91.461%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 1.230s\n",
      "Testing time: 0.058s\n",
      "\n",
      "Accuracy: 98.130%\n",
      "F1 score: 98.087%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 1.009s\n",
      "Testing time: 0.079s\n",
      "\n",
      "Accuracy: 91.284%\n",
      "F1 score: 89.771%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 2.428s\n",
      "Testing time: 0.100s\n",
      "\n",
      "Accuracy: 98.213%\n",
      "F1 score: 98.171%\n",
      "------------------------------------\n",
      "Census Income\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 2.005s\n",
      "Testing time: 0.128s\n",
      "\n",
      "Accuracy: 91.312%\n",
      "F1 score: 89.796%\n",
      "------------------------------------\n",
      "HR\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.005s\n",
      "Testing time: 0.015s\n",
      "\n",
      "Accuracy: 58.252%\n",
      "F1 score: 58.276%\n",
      "------------------------------------\n",
      "HR\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.005s\n",
      "Testing time: 0.014s\n",
      "\n",
      "Accuracy: 67.961%\n",
      "F1 score: 67.145%\n",
      "------------------------------------\n",
      "HR\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.005s\n",
      "Testing time: 0.015s\n",
      "\n",
      "Accuracy: 69.903%\n",
      "F1 score: 67.764%\n",
      "------------------------------------\n",
      "HR\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.004s\n",
      "Testing time: 0.004s\n",
      "\n",
      "Accuracy: 94.175%\n",
      "F1 score: 94.150%\n",
      "------------------------------------\n",
      "HR\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.004s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 94.175%\n",
      "F1 score: 94.150%\n",
      "------------------------------------\n",
      "HR\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.005s\n",
      "Testing time: 0.003s\n",
      "\n",
      "Accuracy: 94.175%\n",
      "F1 score: 94.150%\n",
      "------------------------------------\n",
      "HR\n",
      "Decision Tree with max features None\n",
      "Training time: 0.004s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 99.029%\n",
      "F1 score: 99.028%\n",
      "------------------------------------\n",
      "HR\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.003s\n",
      "Testing time: 0.003s\n",
      "\n",
      "Accuracy: 85.437%\n",
      "F1 score: 85.453%\n",
      "------------------------------------\n",
      "HR\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.004s\n",
      "Testing time: 0.004s\n",
      "\n",
      "Accuracy: 64.078%\n",
      "F1 score: 63.872%\n",
      "------------------------------------\n",
      "HR\n",
      "Support Vector Machine\n",
      "Training time: 0.017s\n",
      "Testing time: 0.014s\n",
      "\n",
      "Accuracy: 65.049%\n",
      "F1 score: 61.398%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.024s\n",
      "Testing time: 0.004s\n",
      "\n",
      "Accuracy: 91.262%\n",
      "F1 score: 91.237%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.017s\n",
      "Testing time: 0.005s\n",
      "\n",
      "Accuracy: 72.816%\n",
      "F1 score: 72.501%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 0.066s\n",
      "Testing time: 0.010s\n",
      "\n",
      "Accuracy: 97.087%\n",
      "F1 score: 97.079%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 0.056s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 78.641%\n",
      "F1 score: 77.861%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 0.115s\n",
      "Testing time: 0.016s\n",
      "\n",
      "Accuracy: 98.058%\n",
      "F1 score: 98.055%\n",
      "------------------------------------\n",
      "HR\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 0.108s\n",
      "Testing time: 0.016s\n",
      "\n",
      "Accuracy: 80.583%\n",
      "F1 score: 79.707%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.002s\n",
      "Testing time: 0.006s\n",
      "\n",
      "Accuracy: 13.333%\n",
      "F1 score: 10.423%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.001s\n",
      "Testing time: 0.007s\n",
      "\n",
      "Accuracy: 13.333%\n",
      "F1 score: 10.292%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.001s\n",
      "Testing time: 0.006s\n",
      "\n",
      "Accuracy: 12.727%\n",
      "F1 score: 11.450%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.007s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.007s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.007s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Decision Tree with max features None\n",
      "Training time: 0.002s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 13.610%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.001s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 13.610%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.001s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 13.610%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Support Vector Machine\n",
      "Training time: 0.027s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 20.000%\n",
      "F1 score: 10.942%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.013s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 18.788%\n",
      "F1 score: 14.926%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.013s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 18.788%\n",
      "F1 score: 14.926%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 0.053s\n",
      "Testing time: 0.008s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 12.835%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 0.055s\n",
      "Testing time: 0.008s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 12.835%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 0.107s\n",
      "Testing time: 0.015s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 13.243%\n",
      "------------------------------------\n",
      "Music BMP\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 0.107s\n",
      "Testing time: 0.016s\n",
      "\n",
      "Accuracy: 17.273%\n",
      "F1 score: 13.243%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.002s\n",
      "Testing time: 0.007s\n",
      "\n",
      "Accuracy: 14.545%\n",
      "F1 score: 13.974%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.001s\n",
      "Testing time: 0.007s\n",
      "\n",
      "Accuracy: 15.455%\n",
      "F1 score: 15.583%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.001s\n",
      "Testing time: 0.007s\n",
      "\n",
      "Accuracy: 15.152%\n",
      "F1 score: 14.704%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.007s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.007s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.007s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 8.182%\n",
      "F1 score: 1.238%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Decision Tree with max features None\n",
      "Training time: 0.005s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 16.667%\n",
      "F1 score: 16.608%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.003s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 22.424%\n",
      "F1 score: 22.204%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.003s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 21.212%\n",
      "F1 score: 21.201%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Support Vector Machine\n",
      "Training time: 0.029s\n",
      "Testing time: 0.013s\n",
      "\n",
      "Accuracy: 22.424%\n",
      "F1 score: 19.081%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.018s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 23.333%\n",
      "F1 score: 22.838%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.021s\n",
      "Testing time: 0.003s\n",
      "\n",
      "Accuracy: 24.848%\n",
      "F1 score: 24.596%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 0.084s\n",
      "Testing time: 0.010s\n",
      "\n",
      "Accuracy: 26.061%\n",
      "F1 score: 25.806%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 0.101s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 24.545%\n",
      "F1 score: 24.424%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 0.165s\n",
      "Testing time: 0.022s\n",
      "\n",
      "Accuracy: 25.152%\n",
      "F1 score: 24.952%\n",
      "------------------------------------\n",
      "Music BMP Statistics\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 0.195s\n",
      "Testing time: 0.019s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 25.513%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.004s\n",
      "Testing time: 0.024s\n",
      "\n",
      "Accuracy: 36.364%\n",
      "F1 score: 34.105%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.003s\n",
      "Testing time: 0.026s\n",
      "\n",
      "Accuracy: 35.152%\n",
      "F1 score: 34.457%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.004s\n",
      "Testing time: 0.026s\n",
      "\n",
      "Accuracy: 35.152%\n",
      "F1 score: 34.102%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.015s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 24.170%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.015s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 24.170%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.015s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 24.170%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Decision Tree with max features None\n",
      "Training time: 0.030s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 35.758%\n",
      "F1 score: 36.099%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.004s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 30.909%\n",
      "F1 score: 31.706%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.003s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 32.424%\n",
      "F1 score: 32.873%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Support Vector Machine\n",
      "Training time: 0.033s\n",
      "Testing time: 0.020s\n",
      "\n",
      "Accuracy: 46.667%\n",
      "F1 score: 46.306%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.034s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 40.909%\n",
      "F1 score: 40.504%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.026s\n",
      "Testing time: 0.003s\n",
      "\n",
      "Accuracy: 43.333%\n",
      "F1 score: 43.053%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 0.158s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 46.970%\n",
      "F1 score: 46.659%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 0.134s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 46.970%\n",
      "F1 score: 45.988%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 0.321s\n",
      "Testing time: 0.018s\n",
      "\n",
      "Accuracy: 46.061%\n",
      "F1 score: 45.690%\n",
      "------------------------------------\n",
      "Music Chroma\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 0.253s\n",
      "Testing time: 0.018s\n",
      "\n",
      "Accuracy: 48.182%\n",
      "F1 score: 47.304%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "kNN with 2 neighbours\n",
      "Training time: 0.003s\n",
      "Testing time: 0.011s\n",
      "\n",
      "Accuracy: 32.424%\n",
      "F1 score: 33.023%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "kNN with 4 neighbours\n",
      "Training time: 0.003s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 36.364%\n",
      "F1 score: 37.555%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "kNN with 6 neighbours\n",
      "Training time: 0.003s\n",
      "Testing time: 0.012s\n",
      "\n",
      "Accuracy: 37.273%\n",
      "F1 score: 37.295%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Perceptron with alpha 0.0001\n",
      "Training time: 0.014s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 18.026%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Perceptron with alpha 0.001\n",
      "Training time: 0.014s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 18.026%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Perceptron with alpha 0.01\n",
      "Training time: 0.015s\n",
      "Testing time: 0.001s\n",
      "\n",
      "Accuracy: 25.758%\n",
      "F1 score: 18.026%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Decision Tree with max features None\n",
      "Training time: 0.047s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 45.455%\n",
      "F1 score: 46.537%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Decision Tree with max features sqrt\n",
      "Training time: 0.006s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 38.182%\n",
      "F1 score: 38.726%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Decision Tree with max features log2\n",
      "Training time: 0.004s\n",
      "Testing time: 0.000s\n",
      "\n",
      "Accuracy: 41.515%\n",
      "F1 score: 41.691%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Support Vector Machine\n",
      "Training time: 0.032s\n",
      "Testing time: 0.019s\n",
      "\n",
      "Accuracy: 70.303%\n",
      "F1 score: 70.375%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 10 trees and sqrt max features\n",
      "Training time: 0.039s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 55.758%\n",
      "F1 score: 55.374%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 10 trees and log2 max features\n",
      "Training time: 0.030s\n",
      "Testing time: 0.002s\n",
      "\n",
      "Accuracy: 56.667%\n",
      "F1 score: 56.456%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 50 trees and sqrt max features\n",
      "Training time: 0.189s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 65.758%\n",
      "F1 score: 65.630%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 50 trees and log2 max features\n",
      "Training time: 0.149s\n",
      "Testing time: 0.009s\n",
      "\n",
      "Accuracy: 66.667%\n",
      "F1 score: 66.437%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 100 trees and sqrt max features\n",
      "Training time: 0.371s\n",
      "Testing time: 0.017s\n",
      "\n",
      "Accuracy: 67.879%\n",
      "F1 score: 67.663%\n",
      "------------------------------------\n",
      "Music MFCC\n",
      "Random forest with 100 trees and log2 max features\n",
      "Training time: 0.290s\n",
      "Testing time: 0.018s\n",
      "\n",
      "Accuracy: 68.788%\n",
      "F1 score: 68.413%\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "testSplitSize = 0.33\n",
    "\n",
    "kNNNeighbours = [2, 4, 6]\n",
    "perceptronAlphaValues = [0.0001, 0.001, 0.01]\n",
    "decisionTreeMaxFeatureValues = [None, 'sqrt', 'log2']\n",
    "randomForestTrees = [10, 50, 100]\n",
    "randomForestMaxFeatureValues = ['sqrt', 'log2']\n",
    "\n",
    "censusIncomeAggregatedResults = []\n",
    "hrAggregatedResults = []\n",
    "musicBmpAggregatedResults = []\n",
    "musicBmpStatisticsAggregatedResults = []\n",
    "musicChromaAggregatedResults = []\n",
    "musicMfccAggregatedResults = []\n",
    "\n",
    "datasets = [\n",
    "    ('Census Income', censusIncomeXAxis, censusIncomeYAxis, censusIncomeAggregatedResults),\n",
    "    ('HR', hrXAxis, hrYAxis, hrAggregatedResults),\n",
    "    ('Music BMP', data_bpm, musicTarget, musicBmpAggregatedResults),\n",
    "    ('Music BMP Statistics', data_bpm_statistics, musicTarget, musicBmpStatisticsAggregatedResults),\n",
    "    ('Music Chroma', data_chroma, musicTarget, musicChromaAggregatedResults),\n",
    "    ('Music MFCC', data_mfcc, musicTarget, musicMfccAggregatedResults),\n",
    "]\n",
    "\n",
    "for _, dataset in enumerate(datasets):\n",
    "    datasetName = dataset[0]\n",
    "    xAxis = dataset[1]\n",
    "    yAxis = dataset[2]\n",
    "    results = dataset[3]\n",
    "\n",
    "    # Shuffle the data, for better results\n",
    "    X, y = shuffle(xAxis, yAxis, random_state=matrikelNumber)\n",
    "\n",
    "    trainData, testData, trainLabels, testLabels = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=testSplitSize,\n",
    "        random_state=matrikelNumber\n",
    "    )\n",
    "\n",
    "    if datasetName == 'Census Income' or datasetName == 'HR':\n",
    "        trainLabels = trainLabels.values\n",
    "\n",
    "    kNNResults = kNearestNeighbours(\n",
    "        datasetName,\n",
    "        kNNNeighbours,\n",
    "        trainData,\n",
    "        testData,\n",
    "        trainLabels,\n",
    "        testLabels\n",
    "    )\n",
    "    results.extend(kNNResults)\n",
    "\n",
    "    perceptronResults = perceptron(\n",
    "        datasetName,\n",
    "        perceptronAlphaValues,\n",
    "        trainData,\n",
    "        testData,\n",
    "        trainLabels,\n",
    "        testLabels\n",
    "    )\n",
    "    results.extend(perceptronResults)\n",
    "\n",
    "    decisionTreeResults = decisionTree(\n",
    "        datasetName,\n",
    "        decisionTreeMaxFeatureValues,\n",
    "        trainData,\n",
    "        testData,\n",
    "        trainLabels,\n",
    "        testLabels\n",
    "    )\n",
    "    results.extend(decisionTreeResults)\n",
    "\n",
    "    supportVectorMachineResults = supportVectorMachine(\n",
    "        datasetName,\n",
    "        trainData,\n",
    "        testData,\n",
    "        trainLabels,\n",
    "        testLabels\n",
    "    )\n",
    "    results.extend(supportVectorMachineResults)\n",
    "\n",
    "    randomForestResults = randomForest(\n",
    "        datasetName,\n",
    "        randomForestTrees,\n",
    "        randomForestMaxFeatureValues,\n",
    "        trainData,\n",
    "        testData,\n",
    "        trainLabels,\n",
    "        testLabels\n",
    "    )\n",
    "    results.extend(randomForestResults)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Census Income"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census Income Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       83.943%  84.432%   \n1                       kNN with \"4\" neighbours       87.847%  86.309%   \n2                       kNN with \"6\" neighbours       88.205%  85.552%   \n3                Perceptron with \"0.0001\" alpha       98.103%  98.093%   \n4                 Perceptron with \"0.001\" alpha       98.103%  98.093%   \n5                  Perceptron with \"0.01\" alpha       98.103%  98.093%   \n6        Decision Tree with \"None\" max features       97.305%  97.323%   \n7        Decision Tree with \"sqrt\" max features       87.902%  87.800%   \n8        Decision Tree with \"log2\" max features       86.142%  85.820%   \n9                                           SVM       96.728%  96.573%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       96.893%  96.775%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       92.356%  91.461%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       98.130%  98.087%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       91.284%  89.771%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       98.213%  98.171%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       91.312%  89.796%   \n\n   trainTime predictionTime  \n0     0.707s        34.247s  \n1     0.640s        34.238s  \n2     0.655s        34.467s  \n3     0.185s         0.012s  \n4     0.161s         0.012s  \n5     0.162s         0.012s  \n6     0.722s         0.010s  \n7     0.055s         0.013s  \n8     0.039s         0.010s  \n9    14.095s         9.431s  \n10    0.283s         0.022s  \n11    0.205s         0.023s  \n12    1.230s         0.058s  \n13    1.009s         0.079s  \n14    2.428s         0.100s  \n15    2.005s         0.128s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>83.943%</td>\n      <td>84.432%</td>\n      <td>0.707s</td>\n      <td>34.247s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>87.847%</td>\n      <td>86.309%</td>\n      <td>0.640s</td>\n      <td>34.238s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>88.205%</td>\n      <td>85.552%</td>\n      <td>0.655s</td>\n      <td>34.467s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>98.103%</td>\n      <td>98.093%</td>\n      <td>0.185s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>98.103%</td>\n      <td>98.093%</td>\n      <td>0.161s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>98.103%</td>\n      <td>98.093%</td>\n      <td>0.162s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>97.305%</td>\n      <td>97.323%</td>\n      <td>0.722s</td>\n      <td>0.010s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>87.902%</td>\n      <td>87.800%</td>\n      <td>0.055s</td>\n      <td>0.013s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>86.142%</td>\n      <td>85.820%</td>\n      <td>0.039s</td>\n      <td>0.010s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>96.728%</td>\n      <td>96.573%</td>\n      <td>14.095s</td>\n      <td>9.431s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>96.893%</td>\n      <td>96.775%</td>\n      <td>0.283s</td>\n      <td>0.022s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>92.356%</td>\n      <td>91.461%</td>\n      <td>0.205s</td>\n      <td>0.023s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>98.130%</td>\n      <td>98.087%</td>\n      <td>1.230s</td>\n      <td>0.058s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>91.284%</td>\n      <td>89.771%</td>\n      <td>1.009s</td>\n      <td>0.079s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>98.213%</td>\n      <td>98.171%</td>\n      <td>2.428s</td>\n      <td>0.100s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>91.312%</td>\n      <td>89.796%</td>\n      <td>2.005s</td>\n      <td>0.128s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Census Income Results:\")\n",
    "censusIncomeDf = pd.DataFrame(censusIncomeAggregatedResults,\n",
    "                              columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime', 'predictionTime'])\n",
    "display(censusIncomeDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `Random forest with 100 trees and sqrt`, closely followed by the `Random forest with 50 trees and sqrt`. The best f1-score was also achieved by the `Random forest with 100 trees and sqrt`.\n",
    "\n",
    "The second-best results of the accuracy-score and f1-score were achieved by the `Perceptron`. All three alpha values achieved the same results in both accuracy- and f1-score.\n",
    "\n",
    "The next best accuracy- and f1-score results were achieved by the `Decision tree with \"None\" max features`.\n",
    "\n",
    "The worst accuracy-score was achieved by `kNN with 2 neighbours`, `Decision tree with \"log2\" max-features` was a bit better.\n",
    "\n",
    "The worst f1-score was achieved by `kNN with 2 neighbours`, `kNN with 6 neighbours` was a bit better.\n",
    "\n",
    "Overall the scores were very good for this dataset, because all values are above 80%.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "Most algorithms had a very short training time. Only 4 executions exceeded 1 second. The `Support Vector Machine` had the longest training time with more than 13 seconds.\n",
    "The training time of the `Random forests` were very short and they achieved the best scores. The training time increases with more trees being added. The training times of the `Perceptron` were also very short and it receives very good scores.\n",
    "\n",
    "\n",
    "The prediction-time was very high for the `kNN`. They exceed the other times many times. They next worst test-times were achieved by the `SVM`. The other testing-times are very good, because they are all below 1 second."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       58.252%  58.276%   \n1                       kNN with \"4\" neighbours       67.961%  67.145%   \n2                       kNN with \"6\" neighbours       69.903%  67.764%   \n3                Perceptron with \"0.0001\" alpha       94.175%  94.150%   \n4                 Perceptron with \"0.001\" alpha       94.175%  94.150%   \n5                  Perceptron with \"0.01\" alpha       94.175%  94.150%   \n6        Decision Tree with \"None\" max features       99.029%  99.028%   \n7        Decision Tree with \"sqrt\" max features       85.437%  85.453%   \n8        Decision Tree with \"log2\" max features       64.078%  63.872%   \n9                                           SVM       65.049%  61.398%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       91.262%  91.237%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       72.816%  72.501%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       97.087%  97.079%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       78.641%  77.861%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       98.058%  98.055%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       80.583%  79.707%   \n\n   trainTime predictionTime  \n0     0.005s         0.015s  \n1     0.005s         0.014s  \n2     0.005s         0.015s  \n3     0.004s         0.004s  \n4     0.004s         0.002s  \n5     0.005s         0.003s  \n6     0.004s         0.002s  \n7     0.003s         0.003s  \n8     0.004s         0.004s  \n9     0.017s         0.014s  \n10    0.024s         0.004s  \n11    0.017s         0.005s  \n12    0.066s         0.010s  \n13    0.056s         0.009s  \n14    0.115s         0.016s  \n15    0.108s         0.016s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>58.252%</td>\n      <td>58.276%</td>\n      <td>0.005s</td>\n      <td>0.015s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>67.961%</td>\n      <td>67.145%</td>\n      <td>0.005s</td>\n      <td>0.014s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>69.903%</td>\n      <td>67.764%</td>\n      <td>0.005s</td>\n      <td>0.015s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>94.175%</td>\n      <td>94.150%</td>\n      <td>0.004s</td>\n      <td>0.004s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>94.175%</td>\n      <td>94.150%</td>\n      <td>0.004s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>94.175%</td>\n      <td>94.150%</td>\n      <td>0.005s</td>\n      <td>0.003s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>99.029%</td>\n      <td>99.028%</td>\n      <td>0.004s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>85.437%</td>\n      <td>85.453%</td>\n      <td>0.003s</td>\n      <td>0.003s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>64.078%</td>\n      <td>63.872%</td>\n      <td>0.004s</td>\n      <td>0.004s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>65.049%</td>\n      <td>61.398%</td>\n      <td>0.017s</td>\n      <td>0.014s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>91.262%</td>\n      <td>91.237%</td>\n      <td>0.024s</td>\n      <td>0.004s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>72.816%</td>\n      <td>72.501%</td>\n      <td>0.017s</td>\n      <td>0.005s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>97.087%</td>\n      <td>97.079%</td>\n      <td>0.066s</td>\n      <td>0.010s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>78.641%</td>\n      <td>77.861%</td>\n      <td>0.056s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>98.058%</td>\n      <td>98.055%</td>\n      <td>0.115s</td>\n      <td>0.016s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>80.583%</td>\n      <td>79.707%</td>\n      <td>0.108s</td>\n      <td>0.016s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"HR Results:\")\n",
    "hrDf = pd.DataFrame(hrAggregatedResults,\n",
    "                    columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime', 'predictionTime'])\n",
    "display(hrDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `Decision Tree with \"None\" max-features`, closely followed by the `Random forest with 100 trees and sqrt`. The best f1-score was also achieved by the `Decision Tree with \"None\" max features`, followed by the `Random forest with 100 trees and sqrt`.\n",
    "\n",
    "The next best results of the accuracy-score and f1-score were achieved by the `Perceptron`. All three alpha values achieved the same results in both accuracy- and f1-score.\n",
    "\n",
    "The worst accuracy-score was achieved by `kNN with 2 neighbours`, followed by the `Decision tree with \"log2\" max-features`.\n",
    "\n",
    "The worst f1-score was achieved by `kNN with 2 neighbours`, followed by the `SVM`.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "All algorithms have a very short training times. The `Random Forest with 100 trees and \"sqrt\" max-features` had the longest training time.\n",
    "The training time of the best `Decision Tree with \"None\" max-features` was very short and achieved the best scores. The training times of the `Perceptron` were also very short, and it receives very good scores.\n",
    "\n",
    "\n",
    "The prediction-time was very high for the `kNN`. They exceed the other times many times. They next worst test-times were achieved by the `svm`. The other testing-times are very good, because they are all below 1 second.\n",
    "\n",
    "The prediction-times are the highest for the `Random-forests with 100 trees`, followed the by the `kNN`. The best time in combination with scores was achieved by the perceptron.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "For the HR dataset the `Decision Tree with \"None\" max-features` delivered the best accuracy- and f1-score. For the Census Income dataset the `Random forest with 100 trees and sqrt` delivered the best results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music BMP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music BMP Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       13.333%  10.423%   \n1                       kNN with \"4\" neighbours       13.333%  10.292%   \n2                       kNN with \"6\" neighbours       12.727%  11.450%   \n3                Perceptron with \"0.0001\" alpha        8.182%   1.238%   \n4                 Perceptron with \"0.001\" alpha        8.182%   1.238%   \n5                  Perceptron with \"0.01\" alpha        8.182%   1.238%   \n6        Decision Tree with \"None\" max features       17.273%  13.610%   \n7        Decision Tree with \"sqrt\" max features       17.273%  13.610%   \n8        Decision Tree with \"log2\" max features       17.273%  13.610%   \n9                                           SVM       20.000%  10.942%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       18.788%  14.926%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       18.788%  14.926%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       17.273%  12.835%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       17.273%  12.835%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       17.273%  13.243%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       17.273%  13.243%   \n\n   trainTime predictionTime  \n0     0.002s         0.006s  \n1     0.001s         0.007s  \n2     0.001s         0.006s  \n3     0.007s         0.000s  \n4     0.007s         0.000s  \n5     0.007s         0.000s  \n6     0.002s         0.000s  \n7     0.001s         0.000s  \n8     0.001s         0.000s  \n9     0.027s         0.012s  \n10    0.013s         0.002s  \n11    0.013s         0.002s  \n12    0.053s         0.008s  \n13    0.055s         0.008s  \n14    0.107s         0.015s  \n15    0.107s         0.016s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>13.333%</td>\n      <td>10.423%</td>\n      <td>0.002s</td>\n      <td>0.006s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>13.333%</td>\n      <td>10.292%</td>\n      <td>0.001s</td>\n      <td>0.007s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>12.727%</td>\n      <td>11.450%</td>\n      <td>0.001s</td>\n      <td>0.006s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>17.273%</td>\n      <td>13.610%</td>\n      <td>0.002s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>17.273%</td>\n      <td>13.610%</td>\n      <td>0.001s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>17.273%</td>\n      <td>13.610%</td>\n      <td>0.001s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>20.000%</td>\n      <td>10.942%</td>\n      <td>0.027s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>18.788%</td>\n      <td>14.926%</td>\n      <td>0.013s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>18.788%</td>\n      <td>14.926%</td>\n      <td>0.013s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>17.273%</td>\n      <td>12.835%</td>\n      <td>0.053s</td>\n      <td>0.008s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>17.273%</td>\n      <td>12.835%</td>\n      <td>0.055s</td>\n      <td>0.008s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>17.273%</td>\n      <td>13.243%</td>\n      <td>0.107s</td>\n      <td>0.015s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>17.273%</td>\n      <td>13.243%</td>\n      <td>0.107s</td>\n      <td>0.016s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Music BMP Results:\")\n",
    "musicBmpDf = pd.DataFrame(musicBmpAggregatedResults,\n",
    "                          columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime', 'predictionTime'])\n",
    "display(musicBmpDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `Support Vector Machine`, closely followed the `Decision Trees`. The best f1-score was achieved by the `Random Forests with 10 trees and \"sqrt\", and \"log2\"`.\n",
    "\n",
    "The next best results of the accuracy-score and f1-score were achieved by the `kNN`.\n",
    "\n",
    "The worst accuracy-score was achieved by the `Perceptron`. The worst f1-score was achieved by the `Perceptron`.\n",
    "\n",
    "Overall the scores were not very good.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "All algorithms have a very short training times. The `Random Forest with 100 trees and \"sqrt\" and \"log2\" max-features` had the longest training times.\n",
    "The training time of the best `SVM` was very short and achieved the best scores.\n",
    "\n",
    "The prediction times are also very short for all datasets.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music BMP Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music BMP Statistics Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       14.545%  13.974%   \n1                       kNN with \"4\" neighbours       15.455%  15.583%   \n2                       kNN with \"6\" neighbours       15.152%  14.704%   \n3                Perceptron with \"0.0001\" alpha        8.182%   1.238%   \n4                 Perceptron with \"0.001\" alpha        8.182%   1.238%   \n5                  Perceptron with \"0.01\" alpha        8.182%   1.238%   \n6        Decision Tree with \"None\" max features       16.667%  16.608%   \n7        Decision Tree with \"sqrt\" max features       22.424%  22.204%   \n8        Decision Tree with \"log2\" max features       21.212%  21.201%   \n9                                           SVM       22.424%  19.081%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       23.333%  22.838%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       24.848%  24.596%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       26.061%  25.806%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       24.545%  24.424%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       25.152%  24.952%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       25.758%  25.513%   \n\n   trainTime predictionTime  \n0     0.002s         0.007s  \n1     0.001s         0.007s  \n2     0.001s         0.007s  \n3     0.007s         0.001s  \n4     0.007s         0.001s  \n5     0.007s         0.000s  \n6     0.005s         0.001s  \n7     0.003s         0.001s  \n8     0.003s         0.001s  \n9     0.029s         0.013s  \n10    0.018s         0.002s  \n11    0.021s         0.003s  \n12    0.084s         0.010s  \n13    0.101s         0.009s  \n14    0.165s         0.022s  \n15    0.195s         0.019s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>14.545%</td>\n      <td>13.974%</td>\n      <td>0.002s</td>\n      <td>0.007s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>15.455%</td>\n      <td>15.583%</td>\n      <td>0.001s</td>\n      <td>0.007s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>15.152%</td>\n      <td>14.704%</td>\n      <td>0.001s</td>\n      <td>0.007s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>8.182%</td>\n      <td>1.238%</td>\n      <td>0.007s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>16.667%</td>\n      <td>16.608%</td>\n      <td>0.005s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>22.424%</td>\n      <td>22.204%</td>\n      <td>0.003s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>21.212%</td>\n      <td>21.201%</td>\n      <td>0.003s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>22.424%</td>\n      <td>19.081%</td>\n      <td>0.029s</td>\n      <td>0.013s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>23.333%</td>\n      <td>22.838%</td>\n      <td>0.018s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>24.848%</td>\n      <td>24.596%</td>\n      <td>0.021s</td>\n      <td>0.003s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>26.061%</td>\n      <td>25.806%</td>\n      <td>0.084s</td>\n      <td>0.010s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>24.545%</td>\n      <td>24.424%</td>\n      <td>0.101s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>25.152%</td>\n      <td>24.952%</td>\n      <td>0.165s</td>\n      <td>0.022s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>25.758%</td>\n      <td>25.513%</td>\n      <td>0.195s</td>\n      <td>0.019s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Music BMP Statistics Results:\")\n",
    "musicBmpStatisticsDf = pd.DataFrame(musicBmpStatisticsAggregatedResults,\n",
    "                                    columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime',\n",
    "                                             'predictionTime'])\n",
    "display(musicBmpStatisticsDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `Random Forest with 50 trees and \"sqrt\" max-feature`, closely followed the `Random Forest with 10 trees and \"log2\" max-feature`. The best f1-score was achieved by the `Random Forest with 50 trees and \"sqrt\" max-feature`.\n",
    "\n",
    "The next best accuracy-score and f1-score of another algorithm were achieved by the `Decision Tree with \"sqrt\"`.\n",
    "\n",
    "The worst accuracy-score was achieved by the `Perceptron`. The worst f1-score was also achieved by the `Perceptron`.\n",
    "\n",
    "Overall the scores were not very good.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "All algorithms have a very short training times. The `Random Forest with 100 trees and \"sqrt\" and \"log2\" max-features` had the longest training times.\n",
    "The training time of the best `Random Forest with 50 trees and \"sqrt\" max-feature` was very short and achieved the best scores.\n",
    "\n",
    "The prediction times are also very short for all datasets.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music Chroma Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music Chroma Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       36.364%  34.105%   \n1                       kNN with \"4\" neighbours       35.152%  34.457%   \n2                       kNN with \"6\" neighbours       35.152%  34.102%   \n3                Perceptron with \"0.0001\" alpha       25.758%  24.170%   \n4                 Perceptron with \"0.001\" alpha       25.758%  24.170%   \n5                  Perceptron with \"0.01\" alpha       25.758%  24.170%   \n6        Decision Tree with \"None\" max features       35.758%  36.099%   \n7        Decision Tree with \"sqrt\" max features       30.909%  31.706%   \n8        Decision Tree with \"log2\" max features       32.424%  32.873%   \n9                                           SVM       46.667%  46.306%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       40.909%  40.504%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       43.333%  43.053%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       46.970%  46.659%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       46.970%  45.988%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       46.061%  45.690%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       48.182%  47.304%   \n\n   trainTime predictionTime  \n0     0.004s         0.024s  \n1     0.003s         0.026s  \n2     0.004s         0.026s  \n3     0.015s         0.001s  \n4     0.015s         0.000s  \n5     0.015s         0.000s  \n6     0.030s         0.000s  \n7     0.004s         0.000s  \n8     0.003s         0.000s  \n9     0.033s         0.020s  \n10    0.034s         0.002s  \n11    0.026s         0.003s  \n12    0.158s         0.009s  \n13    0.134s         0.009s  \n14    0.321s         0.018s  \n15    0.253s         0.018s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>36.364%</td>\n      <td>34.105%</td>\n      <td>0.004s</td>\n      <td>0.024s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>35.152%</td>\n      <td>34.457%</td>\n      <td>0.003s</td>\n      <td>0.026s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>35.152%</td>\n      <td>34.102%</td>\n      <td>0.004s</td>\n      <td>0.026s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>25.758%</td>\n      <td>24.170%</td>\n      <td>0.015s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>25.758%</td>\n      <td>24.170%</td>\n      <td>0.015s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>25.758%</td>\n      <td>24.170%</td>\n      <td>0.015s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>35.758%</td>\n      <td>36.099%</td>\n      <td>0.030s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>30.909%</td>\n      <td>31.706%</td>\n      <td>0.004s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>32.424%</td>\n      <td>32.873%</td>\n      <td>0.003s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>46.667%</td>\n      <td>46.306%</td>\n      <td>0.033s</td>\n      <td>0.020s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>40.909%</td>\n      <td>40.504%</td>\n      <td>0.034s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>43.333%</td>\n      <td>43.053%</td>\n      <td>0.026s</td>\n      <td>0.003s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>46.970%</td>\n      <td>46.659%</td>\n      <td>0.158s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>46.970%</td>\n      <td>45.988%</td>\n      <td>0.134s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>46.061%</td>\n      <td>45.690%</td>\n      <td>0.321s</td>\n      <td>0.018s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>48.182%</td>\n      <td>47.304%</td>\n      <td>0.253s</td>\n      <td>0.018s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Music Chroma Results:\")\n",
    "musicChromaDf = pd.DataFrame(musicChromaAggregatedResults,\n",
    "                             columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime', 'predictionTime'])\n",
    "display(musicChromaDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `Random Forest with 100 trees and \"log2\" max-feature`, directly followed by the `Random Forest with 50 trees and \"sqrt\" max-feature`, `Random Forest with 50 trees and \"log2\" max-feature`. The best f1-score was achieved by the `Random Forest with 100 trees and \"log2\" max-feature`.\n",
    "\n",
    "The next best accuracy-score and f1-score of another algorithm were achieved by the `SVM`.\n",
    "\n",
    "The worst accuracy-score was achieved by the `Perceptron`. The worst f1-score was also achieved by the `Perceptron`.\n",
    "\n",
    "Overall the scores are not very good, but they are better, than the last two datasets.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "All algorithms have a very short training times. The `Random Forest with 100 trees and \"sqrt\" and \"log2\" max-features` had the longest training times.\n",
    "The training time of the `SVM` was very short and achieved very good scores.\n",
    "\n",
    "The prediction times are also very short for all datasets, were the `SVM` has a slightly longer runtime."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Music MFCC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music MFCC Results:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                  algorithmName accuracyScore  f1Score  \\\n0                       kNN with \"2\" neighbours       32.424%  33.023%   \n1                       kNN with \"4\" neighbours       36.364%  37.555%   \n2                       kNN with \"6\" neighbours       37.273%  37.295%   \n3                Perceptron with \"0.0001\" alpha       25.758%  18.026%   \n4                 Perceptron with \"0.001\" alpha       25.758%  18.026%   \n5                  Perceptron with \"0.01\" alpha       25.758%  18.026%   \n6        Decision Tree with \"None\" max features       45.455%  46.537%   \n7        Decision Tree with \"sqrt\" max features       38.182%  38.726%   \n8        Decision Tree with \"log2\" max features       41.515%  41.691%   \n9                                           SVM       70.303%  70.375%   \n10   Random F. (\"10\" trees, \"sqrt\" max feature)       55.758%  55.374%   \n11   Random F. (\"10\" trees, \"log2\" max feature)       56.667%  56.456%   \n12   Random F. (\"50\" trees, \"sqrt\" max feature)       65.758%  65.630%   \n13   Random F. (\"50\" trees, \"log2\" max feature)       66.667%  66.437%   \n14  Random F. (\"100\" trees, \"sqrt\" max feature)       67.879%  67.663%   \n15  Random F. (\"100\" trees, \"log2\" max feature)       68.788%  68.413%   \n\n   trainTime predictionTime  \n0     0.003s         0.011s  \n1     0.003s         0.012s  \n2     0.003s         0.012s  \n3     0.014s         0.002s  \n4     0.014s         0.001s  \n5     0.015s         0.001s  \n6     0.047s         0.000s  \n7     0.006s         0.000s  \n8     0.004s         0.000s  \n9     0.032s         0.019s  \n10    0.039s         0.002s  \n11    0.030s         0.002s  \n12    0.189s         0.009s  \n13    0.149s         0.009s  \n14    0.371s         0.017s  \n15    0.290s         0.018s  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithmName</th>\n      <th>accuracyScore</th>\n      <th>f1Score</th>\n      <th>trainTime</th>\n      <th>predictionTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>kNN with \"2\" neighbours</td>\n      <td>32.424%</td>\n      <td>33.023%</td>\n      <td>0.003s</td>\n      <td>0.011s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kNN with \"4\" neighbours</td>\n      <td>36.364%</td>\n      <td>37.555%</td>\n      <td>0.003s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>kNN with \"6\" neighbours</td>\n      <td>37.273%</td>\n      <td>37.295%</td>\n      <td>0.003s</td>\n      <td>0.012s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Perceptron with \"0.0001\" alpha</td>\n      <td>25.758%</td>\n      <td>18.026%</td>\n      <td>0.014s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Perceptron with \"0.001\" alpha</td>\n      <td>25.758%</td>\n      <td>18.026%</td>\n      <td>0.014s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Perceptron with \"0.01\" alpha</td>\n      <td>25.758%</td>\n      <td>18.026%</td>\n      <td>0.015s</td>\n      <td>0.001s</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Decision Tree with \"None\" max features</td>\n      <td>45.455%</td>\n      <td>46.537%</td>\n      <td>0.047s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Decision Tree with \"sqrt\" max features</td>\n      <td>38.182%</td>\n      <td>38.726%</td>\n      <td>0.006s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Decision Tree with \"log2\" max features</td>\n      <td>41.515%</td>\n      <td>41.691%</td>\n      <td>0.004s</td>\n      <td>0.000s</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SVM</td>\n      <td>70.303%</td>\n      <td>70.375%</td>\n      <td>0.032s</td>\n      <td>0.019s</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random F. (\"10\" trees, \"sqrt\" max feature)</td>\n      <td>55.758%</td>\n      <td>55.374%</td>\n      <td>0.039s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random F. (\"10\" trees, \"log2\" max feature)</td>\n      <td>56.667%</td>\n      <td>56.456%</td>\n      <td>0.030s</td>\n      <td>0.002s</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Random F. (\"50\" trees, \"sqrt\" max feature)</td>\n      <td>65.758%</td>\n      <td>65.630%</td>\n      <td>0.189s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Random F. (\"50\" trees, \"log2\" max feature)</td>\n      <td>66.667%</td>\n      <td>66.437%</td>\n      <td>0.149s</td>\n      <td>0.009s</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Random F. (\"100\" trees, \"sqrt\" max feature)</td>\n      <td>67.879%</td>\n      <td>67.663%</td>\n      <td>0.371s</td>\n      <td>0.017s</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Random F. (\"100\" trees, \"log2\" max feature)</td>\n      <td>68.788%</td>\n      <td>68.413%</td>\n      <td>0.290s</td>\n      <td>0.018s</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Music MFCC Results:\")\n",
    "musicMfccDf = pd.DataFrame(musicMfccAggregatedResults,\n",
    "                           columns=['algorithmName', 'accuracyScore', 'f1Score', 'trainTime', 'predictionTime'])\n",
    "display(musicMfccDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scores\n",
    "\n",
    "The best accuracy-score was achieved by the `SVM`, directly followed by the `Random Forest with 100 trees and \"log2\" max-feature`, `Random Forest with 100 trees and \"sqrt\" max-feature`. The best f1-score was achieved by the `SVM`, followed by the `Random Forest with 100 trees and \"log2\" max-feature`, `Random Forest with 100 trees and \"sqrt\" max-feature`.\n",
    "\n",
    "The next best accuracy-score and f1-score of another algorithm were achieved by the `Decision Tree with \"None\" max-features`, with a massive gap to the other two.\n",
    "\n",
    "The worst accuracy-score was achieved by the `Perceptron`. The worst f1-score was also achieved by the `Perceptron`.\n",
    "\n",
    "Overall the scores are very average, but better than the last music-dataset.\n",
    "\n",
    "#### Training and test-times\n",
    "\n",
    "All algorithms have a very short training times. The `Random Forest with 100 trees and \"sqrt\"` had the longest training times.\n",
    "The training time of the `SVM` was very short and achieved the best scores.\n",
    "\n",
    "The prediction times are also very short for all datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The different extracted features used for training the models, received very different results.\n",
    "\n",
    "**Beats per minute** received very bad classification results. The accuracy-scores span from 8% to 20%. The f1-scores span from 1.2% to ~15%.\n",
    "\n",
    "**Beats per minute statistics** got slightly better results. The accuracy-scores span from 8% to ~26%. The f1-scores span from 1.2% to ~25%.\n",
    "\n",
    "**Music Chroma results** got much better results. The accuracy-scores span from ~25% to ~47%. The f1-scores span from 24% to 47%.\n",
    "\n",
    "**Music MFCC** got even better results. The accuracy scores span from ~26% to 70%. The f1-scores span from 18% to 70%.\n",
    "\n",
    "The training times and prediction-times are very fast for all four datasets. A second was never exceeded for all algorithms."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Music MFCC\n",
      "Best performing algorithm: SVM\n",
      "f1 measure: 0.7037468748954211\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "           blues  classical  country  disco  hiphop   jazz  metal    pop  \\\nblues      0.758      0.000    0.091  0.000   0.000  0.000  0.030  0.000   \nclassical  0.000      0.917    0.000  0.000   0.000  0.083  0.000  0.000   \ncountry    0.000      0.000    0.727  0.030   0.000  0.030  0.030  0.061   \ndisco      0.067      0.000    0.000  0.667   0.000  0.000  0.033  0.033   \nhiphop     0.027      0.000    0.000  0.135   0.459  0.000  0.054  0.108   \njazz       0.000      0.067    0.000  0.000   0.000  0.833  0.000  0.000   \nmetal      0.059      0.000    0.059  0.029   0.029  0.000  0.765  0.000   \npop        0.000      0.000    0.026  0.105   0.026  0.000  0.000  0.789   \nreggae     0.031      0.000    0.062  0.094   0.094  0.031  0.031  0.062   \nrock       0.000      0.000    0.037  0.222   0.000  0.111  0.074  0.037   \n\n           reggae   rock  \nblues       0.000  0.121  \nclassical   0.000  0.000  \ncountry     0.000  0.121  \ndisco       0.067  0.133  \nhiphop      0.189  0.027  \njazz        0.033  0.067  \nmetal       0.000  0.059  \npop         0.026  0.026  \nreggae      0.562  0.031  \nrock        0.000  0.519  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>blues</th>\n      <th>classical</th>\n      <th>country</th>\n      <th>disco</th>\n      <th>hiphop</th>\n      <th>jazz</th>\n      <th>metal</th>\n      <th>pop</th>\n      <th>reggae</th>\n      <th>rock</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>blues</th>\n      <td>0.758</td>\n      <td>0.000</td>\n      <td>0.091</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.030</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.121</td>\n    </tr>\n    <tr>\n      <th>classical</th>\n      <td>0.000</td>\n      <td>0.917</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.083</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>country</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.727</td>\n      <td>0.030</td>\n      <td>0.000</td>\n      <td>0.030</td>\n      <td>0.030</td>\n      <td>0.061</td>\n      <td>0.000</td>\n      <td>0.121</td>\n    </tr>\n    <tr>\n      <th>disco</th>\n      <td>0.067</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.667</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.033</td>\n      <td>0.033</td>\n      <td>0.067</td>\n      <td>0.133</td>\n    </tr>\n    <tr>\n      <th>hiphop</th>\n      <td>0.027</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.135</td>\n      <td>0.459</td>\n      <td>0.000</td>\n      <td>0.054</td>\n      <td>0.108</td>\n      <td>0.189</td>\n      <td>0.027</td>\n    </tr>\n    <tr>\n      <th>jazz</th>\n      <td>0.000</td>\n      <td>0.067</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.033</td>\n      <td>0.067</td>\n    </tr>\n    <tr>\n      <th>metal</th>\n      <td>0.059</td>\n      <td>0.000</td>\n      <td>0.059</td>\n      <td>0.029</td>\n      <td>0.029</td>\n      <td>0.000</td>\n      <td>0.765</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>pop</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.026</td>\n      <td>0.105</td>\n      <td>0.026</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.789</td>\n      <td>0.026</td>\n      <td>0.026</td>\n    </tr>\n    <tr>\n      <th>reggae</th>\n      <td>0.031</td>\n      <td>0.000</td>\n      <td>0.062</td>\n      <td>0.094</td>\n      <td>0.094</td>\n      <td>0.031</td>\n      <td>0.031</td>\n      <td>0.062</td>\n      <td>0.562</td>\n      <td>0.031</td>\n    </tr>\n    <tr>\n      <th>rock</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.037</td>\n      <td>0.222</td>\n      <td>0.000</td>\n      <td>0.111</td>\n      <td>0.074</td>\n      <td>0.037</td>\n      <td>0.000</td>\n      <td>0.519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yTest = le.inverse_transform(bestResult['yTest'])\n",
    "yTestPredicted = le.inverse_transform(bestResult['yTestPredicted'])\n",
    "\n",
    "conf_matrix = pd.DataFrame(\n",
    "    confusion_matrix(\n",
    "        yTest,\n",
    "        yTestPredicted,\n",
    "        labels=list(le.classes_),\n",
    "        normalize='true'\n",
    "    ),\n",
    "    index=list(le.classes_),\n",
    "    columns=list(le.classes_)\n",
    ")\n",
    "\n",
    "conf_matrix = round(conf_matrix, 3)\n",
    "\n",
    "print('Dataset: ' + bestResult['dataset'])\n",
    "print('Best performing algorithm: ' + bestResult['algorithm'])\n",
    "print('f1 measure: ' + str(bestResult['f1Score']) + '\\n')\n",
    "display(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best results were achieved with the `SVM` in the `MFCC`-dataset. The best result was achieved in the genre `classic`. Round about 92% of the tested songs were classified correctly. The other 8% were classified as jazz songs. Aside from jazz no other genre was identified for classic songs.\n",
    "\n",
    "Hiphop was the genre, which was classified the worst. Only 45% were identified correctly. It had the most problems to distinct hiphop songs from reggae, disco and pop songs. About 19% were identified as reggae songs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}